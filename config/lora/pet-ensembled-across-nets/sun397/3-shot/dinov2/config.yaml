algorithm: pet
save_dir: 
  ./saved_models/config/lora/pet-ensembled-across-nets/sun397/3-shot/dinov2
save_name: log
resume: true
load_path: 
  ./saved_models/config/lora/pet-ensembled-across-nets/sun397/3-shot/dinov2/log/latest_model.pth
overwrite: true
use_tensorboard: true
use_wandb: false
epoch: 30
num_train_iter: 80460
num_log_iter: 670
num_eval_iter: 5364
batch_size: 8
eval_batch_size: 16
num_warmup_iter: 2011
num_labels: 1191
ema_m: 0.0
img_size: 224
crop_ratio: 0.875
optim: AdamW
lr: 0.0001
layer_decay: 1.0
momentum: 0.9
weight_decay: 0.0005
amp: false
clip: 0.0
use_cat: true
net: timm/vit_base_patch14_reg4_dinov2.lvd142m
net_from_name: false
data_dir: ./data
dataset: sun397
train_sampler: RandomSampler
num_classes: 397
num_workers: 4
seed: 0
world_size: 1
rank: 0
gpu: None
use_pretrain: true
# VTAB settings
train_split: train
eval_on_test: true
evaluate_unsupervised: false
es_patience: 0.0
# PET settings
w_alpha: 0.0
s_alpha: 0.0
kd_w_alpha: 1.0
kd_s_alpha: 1.0
temperature: 1.0
budget: 1.0
pet_sources:
- "config/lora/supervised/sun397/3-shot/dinov2/dpr-0/train-aug-strong/{'lora_bottleneck':
  16}/lr-1e-3/config.yaml"
- "config/lora/supervised/sun397/3-shot/clip/dpr-0/train-aug-strong/{'lora_bottleneck':
  16}/lr-1e-3/config.yaml"
- "config/adaptformer/supervised/sun397/3-shot/dinov2/dpr-0.2/train-aug-strong/{'adapter_scaler':
  0.1, 'adapter_bottleneck': 4}/lr-1e-3/config.yaml"
- "config/adaptformer/supervised/sun397/3-shot/clip/dpr-0/train-aug-strong/{'adapter_scaler':
  0.1, 'adapter_bottleneck': 16}/lr-1e-3/config.yaml"
pl_selection: balanced-max
logits_ensemble: voting
bootstrapping: true
peft_config:
  method_name: lora
  lora_bottleneck: 4
vit_config:
  drop_path_rate: 0.0
pet_sources_rows:
- - lora
  - supervised
  - sun397
  - 3-shot
  - dinov2
  - "['dpr-0', 'train-aug-strong', \"{'lora_bottleneck': 16}\", 'lr-1e-3']"
  - 657.9205932617188
  - 0.6311722807208052
  - 0.3762303336373158
  - 0.760590887277665
  - 0.3796799058546913
  - 29.685781478881836
  - 0.11459016799926758
  - 0.5286436676979065
  - '2025-12-30 18:02:34'
- - lora
  - supervised
  - sun397
  - 3-shot
  - clip
  - "['dpr-0', 'train-aug-strong', \"{'lora_bottleneck': 16}\", 'lr-1e-3']"
  - 566.0968627929688
  - 0.6174677878667065
  - 0.3555915444619197
  - 0.7525536970460537
  - 0.35940857687038436
  - 35.180362701416016
  - 0.10631376504898071
  - 0.5154023170471191
  - '2025-12-30 18:02:34'
- - adaptformer
  - supervised
  - sun397
  - 3-shot
  - dinov2
  - "['dpr-0.2', 'train-aug-strong', \"{'adapter_scaler': 0.1, 'adapter_bottleneck':
    4}\", 'lr-1e-3']"
  - 601.4793090820312
  - 0.5408119101739446
  - 0.2711671676845907
  - 0.7004079242983952
  - 0.2751303780099587
  - 34.18802261352539
  - 0.11163891106843948
  - 0.43774712085723877
  - '2025-12-30 18:02:35'
- - adaptformer
  - supervised
  - sun397
  - 3-shot
  - clip
  - "['dpr-0', 'train-aug-strong', \"{'adapter_scaler': 0.1, 'adapter_bottleneck':
    16}\", 'lr-1e-3']"
  - 561.7940063476562
  - 0.639375341298478
  - 0.37461098652000635
  - 0.7663403877673006
  - 0.37893520530959013
  - 36.3890266418457
  - 0.10709325969219208
  - 0.564965546131134
  - '2025-12-30 18:02:35'
